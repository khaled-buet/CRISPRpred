
R version 3.2.3 (2015-12-10) -- "Wooden Christmas-Tree"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "crisprpred"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> library('crisprpred')
Loading required package: DAAG
Loading required package: lattice
Loading required package: e1071
Loading required package: h2o
Loading required package: statmod

----------------------------------------------------------------------

Your next step is to start H2O:
    > h2o.init()

For H2O package documentation, ask for help:
    > ??h2o

After starting H2O, you can use the Web UI at http://localhost:54321
For more information visit http://docs.h2o.ai

----------------------------------------------------------------------


Attaching package: ‘h2o’

The following objects are masked from ‘package:stats’:

    sd, var

The following objects are masked from ‘package:base’:

    %*%, %in%, apply, as.factor, as.numeric, colnames, colnames<-,
    ifelse, is.factor, is.numeric, log, trunc

Loading required package: gtools

Attaching package: ‘gtools’

The following object is masked from ‘package:e1071’:

    permutations

Loading required package: earth
Loading required package: plotmo
Loading required package: plotrix
Loading required package: TeachingDemos

Attaching package: ‘crisprpred’

The following object is masked from ‘package:e1071’:

    countpattern

> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("countpattern")
> ### * countpattern
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: countpattern
> ### Title: Illustration of countpattern This function takes sequence and
> ###   pattern as input and count how many times a particular pattern is
> ###   present in the sequence.
> ### Aliases: countpattern
> 
> ### ** Examples
> 
> sequence = list("ABDEFGHABDAACBBDEBGGGHHH", "ABCBDBEBEBBBDBDBFDFDFGGHHEEFFEECCCD")
> pattern = "BD"
> feat = featurization(sequence, pattern)
1  order seq. features: 1 :total features =  1 
2  order seq. features: 1 :total features =  2 
1 order pos. features: 24 :total features =  26 
2 order pos. features: 23 :total features =  49 
> feat
  BD BDBD BD_1 BD_2 BD_3 BD_4 BD_5 BD_6 BD_7 BD_8 BD_9 BD_10 BD_11 BD_12 BD_13
1  3    0    0    1    0    0    0    0    0    0    1     0     0     0     0
2  3    1    0    0    0    1    0    0    0    0    0     0     0     1     0
  BD_14 BD_15 BD_16 BD_17 BD_18 BD_19 BD_20 BD_21 BD_22 BD_23 BD_24 BDBD_1
1     0     1     0     0     0     0     0     0     0     0     0      0
2     1     0     0     0     0     0     0     0     0     0     0      0
  BDBD_2 BDBD_3 BDBD_4 BDBD_5 BDBD_6 BDBD_7 BDBD_8 BDBD_9 BDBD_10 BDBD_11
1      0      0      0      0      0      0      0      0       0       0
2      0      0      0      0      0      0      0      0       0       0
  BDBD_12 BDBD_13 BDBD_14 BDBD_15 BDBD_16 BDBD_17 BDBD_18 BDBD_19 BDBD_20
1       0       0       0       0       0       0       0       0       0
2       1       0       0       0       0       0       0       0       0
  BDBD_21 BDBD_22 BDBD_23 mfe       heat
1       0       0       0   0 0.00590605
2       0       0       0   0 0.11064000
> 
> 
> 
> cleanEx()
> nameEx("crisprpred_main")
> ### * crisprpred_main
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: crisprpred_main
> ### Title: Explanation of crisprpred_main functions
> ### Aliases: crisprpred_main
> 
> ### ** Examples
> 
> setwd('..')
> #suppose we have a file as '../crisprpred/data-raw/sample.csv' and current directory is set to '../crisprpred'
> dir = getwd()
> datasetpath = paste0(dir,'/data-raw/sample.csv')
> featurelist = c("X30mer", "Percent.Peptide", "Amino.Acid.Cut.position","predictions")
> kfoldCross = 2
> crisprpred_main(datasetpath, featurelist, kfoldCross, 3, 4, 0.66)
Warning in predict.lm(model1, testing) :
  prediction from a rank-deficient fit may be misleading
Warning in predict.lm(model1, testing) :
  prediction from a rank-deficient fit may be misleading
Warning in predict.lm(model1, testing) :
  prediction from a rank-deficient fit may be misleading
Warning in predict.lm(model1, testing) :
  prediction from a rank-deficient fit may be misleading
Warning in predict.lm(model1, testing) :
  prediction from a rank-deficient fit may be misleading
Warning in predict.lm(model1, testing) :
  prediction from a rank-deficient fit may be misleading
Warning in predict.lm(model1, testing) :
  prediction from a rank-deficient fit may be misleading
Warning in predict.lm(model1, testing) :
  prediction from a rank-deficient fit may be misleading
Warning in predict.lm(model1, testing) :
  prediction from a rank-deficient fit may be misleading
Warning in predict.lm(model1, testing) :
  prediction from a rank-deficient fit may be misleading
Warning in predict.lm(model1, testing) :
  prediction from a rank-deficient fit may be misleading
Warning in predict.lm(model1, testing) :
  prediction from a rank-deficient fit may be misleading
Warning in predict.lm(model1, testing) :
  prediction from a rank-deficient fit may be misleading
Warning in predict.lm(model1, testing) :
  prediction from a rank-deficient fit may be misleading
Warning in predict.lm(model1, testing) :
  prediction from a rank-deficient fit may be misleading
Warning in predict.lm(model1, testing) :
  prediction from a rank-deficient fit may be misleading
Warning in predict.lm(model1, testing) :
  prediction from a rank-deficient fit may be misleading
LR Regression RMSE (leave one gene out): 1.770275e-15 8.957076e-16 6.773473e-16 3.741492e-16 5.280858e-16 1.08389e-15 3.515706e-16 6.713178e-16 9.48575e-16 8.575829e-16 2.651348e-16 9.244917e-16 7.850462e-16 1.067778e-15 7.850462e-17 NaN NaN 
Spearman Cor. for LR (leave one gene out): 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 NA NA 
Warning in stats::cor(as.vector(predictionsS), as.vector(testing$predictions),  :
  the standard deviation is zero
SVM Regression RMSE (leave one gene out): 0.04674167 0.1103352 0.1586749 0.131763 0.1316052 0.05996369 0.0893627 0.05813836 0.01304371 0.05690993 0.1647353 0.1400374 0.2764606 0.0604458 0.0575573 NaN NaN 
Spearman Cor. for SVM (leave one gene out): 0.7 0.7684705 0.1087876 0.3333333 NA 0.4 -0.2333333 0.8 1 0.5 0.8 0.3166667 1 -1 -1 NA NA 
 [1]  0.7000000  0.7684705  0.1087876  0.3333333         NA  0.4000000
 [7] -0.2333333  0.8000000  1.0000000  0.5000000  0.8000000  0.3166667
[13]  1.0000000 -1.0000000 -1.0000000         NA         NA
> 
> 
> 
> cleanEx()
> nameEx("dplearning")
> ### * dplearning
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: dplearning
> ### Title: Deep Learning
> ### Aliases: dplearning
> 
> ### ** Examples
> 
> featurelist = c("Percent.Peptide", "Amino.Acid.Cut.position","predictions")
> #suppose we have a file as '../crisprpred/data-raw/sample.csv' and current directory is set to '../crisprpred'
> dir = getwd()
> filepath = paste0(dir,'/data-raw/sample.csv')
> data = read.csv(filepath)
> dplearning(featurelist,data)

H2O is not running yet, starting it now...

Note:  In case of errors look at the following log files:
    /tmp/Rtmp4odKx0/h2o_khaled_started_from_r.out
    /tmp/Rtmp4odKx0/h2o_khaled_started_from_r.err

java version "1.7.0_101"
OpenJDK Runtime Environment (IcedTea 2.6.6) (7u101-2.6.6-0ubuntu0.15.10.1)
OpenJDK 64-Bit Server VM (build 24.95-b01, mixed mode)

..Successfully connected to http://127.0.0.1:54321/ 

R is connected to the H2O cluster: 
    H2O cluster uptime:         2 seconds 378 milliseconds 
    H2O cluster version:        3.6.0.8 
    H2O cluster name:           H2O_started_from_R_khaled_gjo928 
    H2O cluster total nodes:    1 
    H2O cluster total memory:   0.84 GB 
    H2O cluster total cores:    4 
    H2O cluster allowed cores:  2 
    H2O cluster healthy:        TRUE 

Note:  As started, H2O is limited to the CRAN default of 2 CPUs.
       Shut down and restart H2O as shown below to use all your CPUs.
           > h2o.shutdown()
           > h2o.init(nthreads = -1)

  |                                                                              |                                                                      |   0%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==                                                                    |   3%  |                                                                              |======                                                                |   8%  |                                                                              |=======                                                               |  10%  |                                                                              |===========                                                           |  16%  |                                                                              |=================                                                     |  24%  |                                                                              |===================                                                   |  27%  |                                                                              |=======================                                               |  33%  |                                                                              |===========================                                           |  38%  |                                                                              |=============================                                         |  41%  |                                                                              |==================================                                    |  49%  |                                                                              |====================================                                  |  52%  |                                                                              |=======================================                               |  56%  |                                                                              |============================================                          |  63%  |                                                                              |=============================================                         |  65%  |                                                                              |==================================================                    |  72%  |                                                                              |===================================================                   |  73%  |                                                                              |========================================================              |  80%  |                                                                              |==========================================================            |  83%  |                                                                              |======================================================================| 100%
Deep Learning RMSE (n-fold): 0.1011324 0.1128838 0.105876 0.1692252 0.1299589 0.1300944 0.06395574 0.09471673 0.07699963 
Spearman Cor. for DL (n-fold): 0.1324201 0.1363636 0.5688073 0.1050228 0.6727273 0.440367 0.8272727 -0.1506849 0.587156 
[1]  0.1324201  0.1363636  0.5688073  0.1050228  0.6727273  0.4403670  0.8272727
[8] -0.1506849  0.5871560
> 
> 
> 
> cleanEx()
> nameEx("featureformula")
> ### * featureformula
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: featureformula
> ### Title: Making Formula for Learning
> ### Aliases: featureformula
> 
> ### ** Examples
> 
> featurelist = c('X1', 'X2', 'X3', 'Y')
> formula = featureformula(featurelist)
> formula
[1] "Y~X1+X2+X3"
> 
> 
> 
> cleanEx()
> nameEx("featurization")
> ### * featurization
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: featurization
> ### Title: Illustration of Featurization
> ### Aliases: featurization
> 
> ### ** Examples
> 
> input = list("ABCDEFGHABDAACBBDEBGGGHHH", "ABCBDBEBEBBBDBDBFDFDFGGHHEEFFEECCCD")
> string = c("A", "BD")
> featuredata = featurization(input, string, seq = TRUE, pos = FALSE)
1  order seq. features: 2 :total features =  2 
2  order seq. features: 4 :total features =  6 
> featuredata
  A BD AA ABD BDA BDBD mfe       heat
1 4  2  1   1   1    0   0 0.00607864
2 1  3  0   0   0    1   0 0.11064000
> 
> 
> 
> cleanEx()
> nameEx("findposition")
> ### * findposition
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: findposition
> ### Title: Illustration of findposition This function takes sequence,
> ###   pattern and position as input and check whether a particulaer pattern
> ###   is present in position-th place of sequence.
> ### Aliases: findposition
> 
> ### ** Examples
> 
> sequence = list("ABDEFGHABDAACBBDEBGGGHHH", "ABCBDBEBEBBBDBDBFDFDFGGHHEEFFEECCCD")
> pattern = "BD"
> position = 2
> feat = featurization(sequence, pattern, position)
1 order pos. features: 24 :total features =  24 
2 order pos. features: 23 :total features =  47 
> feat
  BD_1 BD_2 BD_3 BD_4 BD_5 BD_6 BD_7 BD_8 BD_9 BD_10 BD_11 BD_12 BD_13 BD_14
1    0    1    0    0    0    0    0    0    1     0     0     0     0     0
2    0    0    0    1    0    0    0    0    0     0     0     1     0     1
  BD_15 BD_16 BD_17 BD_18 BD_19 BD_20 BD_21 BD_22 BD_23 BD_24 BDBD_1 BDBD_2
1     1     0     0     0     0     0     0     0     0     0      0      0
2     0     0     0     0     0     0     0     0     0     0      0      0
  BDBD_3 BDBD_4 BDBD_5 BDBD_6 BDBD_7 BDBD_8 BDBD_9 BDBD_10 BDBD_11 BDBD_12
1      0      0      0      0      0      0      0       0       0       0
2      0      0      0      0      0      0      0       0       0       1
  BDBD_13 BDBD_14 BDBD_15 BDBD_16 BDBD_17 BDBD_18 BDBD_19 BDBD_20 BDBD_21
1       0       0       0       0       0       0       0       0       0
2       0       0       0       0       0       0       0       0       0
  BDBD_22 BDBD_23 mfe       heat
1       0       0   0 0.00590605
2       0       0   0 0.11064000
> 
> 
> 
> cleanEx()
> nameEx("lmregression")
> ### * lmregression
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: lmregression
> ### Title: Linear Regression
> ### Aliases: lmregression
> 
> ### ** Examples
> 
> featurelist = c("Percent.Peptide", "Amino.Acid.Cut.position","predictions")
> dir = getwd()
> filepath = paste0(dir,'/data-raw/sample.csv')
> data = read.csv(filepath)
> lmregression(featurelist,data,0)
Analysis of Variance Table

Response: predictions
                        Df Sum Sq Mean Sq F value  Pr(>F)    
Percent.Peptide          1  0.368   0.368   25.96 1.7e-06 ***
Amino.Acid.Cut.position  1  0.013   0.013    0.88    0.35    
Residuals               98  1.388   0.014                    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


Warning in CVlm(data = featuredata, form.lm = model1, m = kfold) :
  

 As there is >1 explanatory variable, cross-validation
 predicted values for a fold are not a linear function
 of corresponding overall predicted values.  Lines that
 are shown for the different folds are approximate


fold 1 
Observations in test set: 10 
                11      20    22     29     32     37       44      53    59
Predicted    0.475  0.6021 0.485  0.505  0.475  0.434  0.59283  0.4134 0.540
cvpred       0.494  0.5983 0.480  0.516  0.494  0.457  0.59354  0.4079 0.538
predictions  0.375  0.5083 0.592  0.340  0.384  0.226  0.58932  0.3890 0.640
CV residual -0.118 -0.0899 0.111 -0.176 -0.110 -0.231 -0.00422 -0.0188 0.102
                65
Predicted   0.4700
cvpred      0.4831
predictions 0.5761
CV residual 0.0929

Sum of squares = 0.15    Mean square = 0.02    n = 10 

fold 2 
Observations in test set: 11 
                 1     3     18     38    42      52    55      67    68     69
Predicted   0.4832 0.462  0.609 0.6146 0.460 0.45063 0.495  0.4563 0.419 0.4163
cvpred      0.4720 0.448  0.616 0.6217 0.447 0.43436 0.486  0.4424 0.408 0.4045
predictions 0.5444 0.476  0.410 0.6728 0.585 0.44064 0.727  0.3776 0.514 0.4454
CV residual 0.0724 0.028 -0.206 0.0511 0.138 0.00628 0.242 -0.0648 0.106 0.0408
                86
Predicted   0.5008
cvpred      0.4924
predictions 0.5488
CV residual 0.0564

Sum of squares = 0.15    Mean square = 0.01    n = 11 

fold 3 
Observations in test set: 10 
                  4      8       9      10     16     45    62     63     78
Predicted    0.4899 0.5174  0.5825  0.5825  0.414  0.488 0.508  0.446 0.6021
cvpred       0.5033 0.5262  0.5801  0.5801  0.439  0.495 0.512  0.456 0.5968
predictions  0.4599 0.6194  0.4947  0.4947  0.240  0.461 0.547  0.330 0.6817
CV residual -0.0434 0.0932 -0.0854 -0.0854 -0.199 -0.034 0.035 -0.126 0.0849
                92
Predicted    0.405
cvpred       0.430
predictions  0.171
CV residual -0.259

Sum of squares = 0.16    Mean square = 0.02    n = 10 

fold 4 
Observations in test set: 10 
                 30     34    35     47     56    74      82     96     99
Predicted    0.5827  0.597 0.476 0.5928  0.614 0.468  0.5378 0.5244  0.393
cvpred       0.5930  0.609 0.477 0.6038  0.627 0.471  0.5453 0.5311  0.385
predictions  0.5546  0.192 0.706 0.6781  0.484 0.630  0.4861 0.5451  0.241
CV residual -0.0383 -0.417 0.229 0.0743 -0.142 0.159 -0.0593 0.0139 -0.144
               100
Predicted    0.456
cvpred       0.460
predictions  0.243
CV residual -0.217

Sum of squares = 0.35    Mean square = 0.04    n = 10 

fold 5 
Observations in test set: 10 
               21      39     50     51    54    64      71    81      89
Predicted   0.534  0.6157 0.5255  0.406 0.518 0.528  0.5953 0.588  0.4891
cvpred      0.527  0.6107 0.5202  0.418 0.515 0.530  0.5898 0.583  0.4830
predictions 0.642  0.5941 0.5706  0.232 0.674 0.571  0.5035 0.651  0.4556
CV residual 0.115 -0.0166 0.0504 -0.187 0.159 0.041 -0.0863 0.068 -0.0273
                94
Predicted   0.4670
cvpred      0.4597
predictions 0.5072
CV residual 0.0475

Sum of squares = 0.09    Mean square = 0.01    n = 10 

fold 6 
Observations in test set: 10 
                2      24     40      58    75      80      87     93      95
Predicted   0.469  0.5352 0.5567  0.4747 0.573  0.6050  0.5923  0.405  0.6150
cvpred      0.472  0.5391 0.5596  0.4784 0.576  0.6078  0.5951  0.409  0.6176
predictions 0.618  0.4439 0.6299  0.4337 0.620  0.5120  0.5618  0.171  0.6002
CV residual 0.145 -0.0952 0.0703 -0.0447 0.044 -0.0957 -0.0333 -0.239 -0.0174
               101
Predicted    0.600
cvpred       0.603
predictions  0.501
CV residual -0.102

Sum of squares = 0.12    Mean square = 0.01    n = 10 

fold 7 
Observations in test set: 10 
                 12     14     15     19      31       33    60     72      77
Predicted    0.5007 0.5354 0.4768 0.5401  0.5827  0.57924 0.540 0.5612  0.6047
cvpred       0.4988 0.5333 0.4740 0.5369  0.5800  0.57616 0.539 0.5581  0.6011
predictions  0.4143 0.6175 0.5004 0.5861  0.5546  0.57133 0.640 0.6508  0.5747
CV residual -0.0844 0.0842 0.0264 0.0493 -0.0253 -0.00483 0.102 0.0928 -0.0263
                 98
Predicted    0.4415
cvpred       0.4451
predictions  0.3545
CV residual -0.0906

Sum of squares = 0.05    Mean square = 0    n = 10 

fold 8 
Observations in test set: 10 
                 5    13     17     23      27    28    36      57      83
Predicted    0.609 0.468 0.4809 0.5762  0.4262 0.534 0.476  0.4747  0.5403
cvpred       0.617 0.458 0.4718 0.5809  0.4156 0.532 0.470  0.4690  0.5399
predictions  0.291 0.561 0.5123 0.6314  0.3551 0.671 0.706  0.4337  0.4816
CV residual -0.326 0.103 0.0405 0.0505 -0.0605 0.139 0.236 -0.0353 -0.0583
               90
Predicted   0.494
cvpred      0.491
predictions 0.669
CV residual 0.179

Sum of squares = 0.24    Mean square = 0.02    n = 10 

fold 9 
Observations in test set: 10 
                25    41    49      61     66      70      73     79     84
Predicted   0.5944 0.575 0.509  0.4710 0.5662  0.5684  0.4753  0.493 0.4386
cvpred      0.5881 0.570 0.505  0.4679 0.5622  0.5630  0.4764  0.493 0.4418
predictions 0.6305 0.747 0.615  0.4295 0.6244  0.5168  0.4310  0.446 0.4555
CV residual 0.0424 0.177 0.110 -0.0384 0.0622 -0.0462 -0.0454 -0.047 0.0136
                97
Predicted   0.5254
cvpred      0.5210
predictions 0.5569
CV residual 0.0358

Sum of squares = 0.06    Mean square = 0.01    n = 10 

fold 10 
Observations in test set: 10 
                6      7     26     43    46      48     76     85      88
Predicted   0.464 0.5212  0.426 0.4710 0.487  0.5359 0.5734 0.5152  0.5923
cvpred      0.451 0.5170  0.413 0.4675 0.474  0.5310 0.5670 0.5101  0.5867
predictions 0.570 0.5925  0.355 0.5404 0.720  0.4997 0.6203 0.5916  0.5618
CV residual 0.120 0.0755 -0.058 0.0729 0.246 -0.0313 0.0534 0.0815 -0.0249
               91
Predicted   0.494
cvpred      0.484
predictions 0.669
CV residual 0.185

Sum of squares = 0.13    Mean square = 0.01    n = 10 

Overall (Sum over all 10 folds) 
    ms 
0.0148 
LR Regression RMSE (n-fold): 0.128 0.107 0.0923 0.181 0.12 0.117 0.074 0.0803 0.0868 
Spearman Cor. for LR (n-fold): -0.187 0.336 0.413 0.0137 0.473 0.771 0.464 0.105 0.229 
[1] -0.1872  0.3364  0.4128  0.0137  0.4727  0.7706  0.4636  0.1050  0.2294
> 
> 
> 
> cleanEx()
> nameEx("mars")
> ### * mars
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: mars
> ### Title: MARS Regression
> ### Aliases: mars
> 
> ### ** Examples
> 
> featurelist = c("Percent.Peptide", "Amino.Acid.Cut.position","predictions")
> dir = getwd()
> filepath = paste0(dir,'/data-raw/sample.csv')
> data = read.csv(filepath)
> mars(featurelist,data,0,2)
MARS Regression RMSE (n-fold): 0.11 
Spearman Cor. for MARS (n-fold): 0.501 
[1] 0.501
> 
> 
> 
> cleanEx()
> nameEx("randomforest")
> ### * randomforest
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: randomforest
> ### Title: Random Forest
> ### Aliases: randomforest
> 
> ### ** Examples
> 
> featurelist = c("Percent.Peptide", "Amino.Acid.Cut.position","predictions")
> #suppose we have a file as '../crisprpred/data-raw/sample.csv' and current directory is set to '../crisprpred'
> dir = getwd()
> filepath = paste0(dir,'/data-raw/sample.csv')
> data = read.csv(filepath)
> randomforest(featurelist,data)
Successfully connected to http://127.0.0.1:54321/ 

R is connected to the H2O cluster: 
    H2O cluster uptime:         26 seconds 224 milliseconds 
    H2O cluster version:        3.6.0.8 
    H2O cluster name:           H2O_started_from_R_khaled_gjo928 
    H2O cluster total nodes:    1 
    H2O cluster total memory:   0.84 GB 
    H2O cluster total cores:    4 
    H2O cluster allowed cores:  2 
    H2O cluster healthy:        TRUE 

  |                                                                              |                                                                      |   0%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |======                                                                |   9%  |                                                                              |=========================                                             |  36%  |                                                                              |====================================================                  |  74%  |                                                                              |======================================================================| 100%
Random Forest RMSE (n-fold): 0.0398 0.0376 0.044 0.0522 0.0456 0.0456 0.029 0.0458 0.022 
Spearman Cor. for RF (n-fold): 0.909 0.9 0.908 0.945 0.955 0.917 0.936 0.781 0.991 
[1] 0.909 0.900 0.908 0.945 0.955 0.917 0.936 0.781 0.991
> 
> 
> 
> cleanEx()
> nameEx("randomforest0")
> ### * randomforest0
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: randomforest0
> ### Title: Random Forest
> ### Aliases: randomforest0
> 
> ### ** Examples
> 
> featurelist = c("Percent.Peptide", "Amino.Acid.Cut.position","predictions")
> #suppose we have a file as '../crisprpred/data-raw/sample.csv' and current directory is set to '../crisprpred'
> dir = getwd()
> filepath = paste0(dir,'/data-raw/sample.csv')
> data = read.csv(filepath)
> randomforest(featurelist,data,leaveonegene = 0)
Successfully connected to http://127.0.0.1:54321/ 

R is connected to the H2O cluster: 
    H2O cluster uptime:         31 seconds 131 milliseconds 
    H2O cluster version:        3.6.0.8 
    H2O cluster name:           H2O_started_from_R_khaled_gjo928 
    H2O cluster total nodes:    1 
    H2O cluster total memory:   0.84 GB 
    H2O cluster total cores:    4 
    H2O cluster allowed cores:  2 
    H2O cluster healthy:        TRUE 

  |                                                                              |                                                                      |   0%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |=                                                                     |   1%  |                                                                              |=============================                                         |  41%  |                                                                              |======================================================================| 100%
Random Forest RMSE (n-fold): 0.0362 0.0365 0.0424 0.0564 0.0501 0.045 0.0378 0.0487 0.024 
Spearman Cor. for RF (n-fold): 0.963 0.918 0.927 0.936 0.891 0.917 0.918 0.726 0.991 
[1] 0.963 0.918 0.927 0.936 0.891 0.917 0.918 0.726 0.991
> 
> 
> 
> cleanEx()
> nameEx("rmse")
> ### * rmse
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: rmse
> ### Title: Root Mean Square Error
> ### Aliases: rmse
> 
> ### ** Examples
> 
> rmse(5)
[1] 5
> 
> 
> 
> cleanEx()
> nameEx("svmregression")
> ### * svmregression
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: svmregression
> ### Title: SMV Regression
> ### Aliases: svmregression
> 
> ### ** Examples
> 
> featurelist = c("Percent.Peptide", "Amino.Acid.Cut.position","predictions")
> dir = getwd()
> filepath = paste0(dir,'/data-raw/sample.csv')
> data = read.csv(filepath)
> svmregression(featurelist,data,0)
SVM Regression RMSE (n-fold): 0.104 0.0823 0.0936 0.151 0.0889 0.0987 0.0924 0.0885 0.0679 
Spearman Cor. for SVM (n-fold): 0.333 0.5 0.431 0.525 0.427 0.697 0.727 -0.032 0.587 
[1]  0.333  0.500  0.431  0.525  0.427  0.697  0.727 -0.032  0.587
> 
> 
> 
> cleanEx()
> nameEx("viennaRNADataManipulation")
> ### * viennaRNADataManipulation
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: viennaRNADataManipulation
> ### Title: Description of viennaRNADataManipulation Function
> ### Aliases: viennaRNADataManipulation
> 
> ### ** Examples
> 
> s = c('AGGCGTGTTAACT','ACGTTTAAGCT')
> viennaRNADataManipulation(s)
  mfe   heat
1   0 0.1832
2   0 0.0552
> 
> 
> 
> ### * <FOOTER>
> ###
> options(digits = 7L)
> base::cat("Time elapsed: ", proc.time() - base::get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  3.188 0.096 36.31 0.472 0.016 
> grDevices::dev.off()
null device 
          1 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
